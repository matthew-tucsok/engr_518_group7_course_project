{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (8.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (1.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: setuptools-scm>=4 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from matplotlib) (4.28.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from setuptools-scm>=4->matplotlib) (57.0.0)\n",
      "Requirement already satisfied: numba in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (0.54.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from numba) (57.0.0)\n",
      "Requirement already satisfied: numpy<1.21,>=1.17 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from numba) (1.20.3)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\users\\mattt\\desktop\\pycharm projects\\engr_518_group7_course_project\\2d classifier\\venv\\lib\\site-packages (from numba) (0.37.0)\n"
     ]
    }
   ],
   "source": [
    "import zipfile as zf\n",
    "\n",
    "zip_files = zf.ZipFile(\"ENGR_518_group_2_datasets.zip\", 'r')\n",
    "zip_files.extractall()\n",
    "zip_files.close()\n",
    "\n",
    "!pip install pillow\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "1506 flat images and 1494 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.7737665176391602\n",
      "Total execution for 80 iterations: 0.9589338302612305\n",
      "Best weights after iteration 79 with a cost of 0.3361330175073247\n",
      "494 flat images and 506 non-flat images in test set.\n",
      "[[1321  173]\n",
      " [ 277 1229]]\n",
      "Training Accuracy: 85.0 %\n",
      "[[451  55]\n",
      " [ 82 412]]\n",
      "Testing Accuracy: 86.3 %\n",
      "Run 2\n",
      "1478 flat images and 1522 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 48 iterations: 0.12411332130432129\n",
      "Best weights after iteration 47 with a cost of 0.32806378991151675\n",
      "522 flat images and 478 non-flat images in test set.\n",
      "[[1348  174]\n",
      " [ 257 1221]]\n",
      "Training Accuracy: 85.63333333333334 %\n",
      "[[417  61]\n",
      " [ 96 426]]\n",
      "Testing Accuracy: 84.3 %\n",
      "Run 3\n",
      "1501 flat images and 1499 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0010004043579101562\n",
      "Total execution for 17 iterations: 0.04103684425354004\n",
      "Best weights after iteration 6 with a cost of 0.3372072103514684\n",
      "499 flat images and 501 non-flat images in test set.\n",
      "[[1334  165]\n",
      " [ 276 1225]]\n",
      "Training Accuracy: 85.3 %\n",
      "[[450  51]\n",
      " [ 97 402]]\n",
      "Testing Accuracy: 85.2 %\n",
      "Run 4\n",
      "1483 flat images and 1517 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 48 iterations: 0.12311172485351562\n",
      "Best weights after iteration 47 with a cost of 0.3313927538705017\n",
      "517 flat images and 483 non-flat images in test set.\n",
      "[[1348  169]\n",
      " [ 265 1218]]\n",
      "Training Accuracy: 85.53333333333333 %\n",
      "[[430  53]\n",
      " [ 98 419]]\n",
      "Testing Accuracy: 84.9 %\n",
      "Run 5\n",
      "1504 flat images and 1496 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.001001119613647461\n",
      "Total execution for 25 iterations: 0.06505894660949707\n",
      "Best weights after iteration 24 with a cost of 0.32432481481621617\n",
      "496 flat images and 504 non-flat images in test set.\n",
      "[[1299  197]\n",
      " [ 231 1273]]\n",
      "Training Accuracy: 85.73333333333333 %\n",
      "[[435  69]\n",
      " [ 83 413]]\n",
      "Testing Accuracy: 84.8 %\n",
      "Run 6\n",
      "1492 flat images and 1508 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 15 iterations: 0.04303908348083496\n",
      "Best weights after iteration 14 with a cost of 0.3369354777242047\n",
      "508 flat images and 492 non-flat images in test set.\n",
      "[[1339  169]\n",
      " [ 279 1213]]\n",
      "Training Accuracy: 85.06666666666666 %\n",
      "[[448  44]\n",
      " [ 95 413]]\n",
      "Testing Accuracy: 86.1 %\n",
      "Run 7\n",
      "1492 flat images and 1508 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 21 iterations: 0.05605125427246094\n",
      "Best weights after iteration 5 with a cost of 0.3339581688512462\n",
      "508 flat images and 492 non-flat images in test set.\n",
      "[[1351  157]\n",
      " [ 281 1211]]\n",
      "Training Accuracy: 85.4 %\n",
      "[[441  51]\n",
      " [100 408]]\n",
      "Testing Accuracy: 84.9 %\n",
      "Run 8\n",
      "1500 flat images and 1500 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 55 iterations: 0.1411275863647461\n",
      "Best weights after iteration 54 with a cost of 0.3380971882804874\n",
      "500 flat images and 500 non-flat images in test set.\n",
      "[[1337  163]\n",
      " [ 283 1217]]\n",
      "Training Accuracy: 85.13333333333334 %\n",
      "[[457  43]\n",
      " [ 98 402]]\n",
      "Testing Accuracy: 85.9 %\n",
      "Run 9\n",
      "1499 flat images and 1501 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 24 iterations: 0.057051658630371094\n",
      "Best weights after iteration 23 with a cost of 0.33076777165775867\n",
      "501 flat images and 499 non-flat images in test set.\n",
      "[[1316  185]\n",
      " [ 248 1251]]\n",
      "Training Accuracy: 85.56666666666666 %\n",
      "[[437  62]\n",
      " [ 89 412]]\n",
      "Testing Accuracy: 84.9 %\n",
      "Run 10\n",
      "1512 flat images and 1488 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 23 iterations: 0.05004477500915527\n",
      "Best weights after iteration 10 with a cost of 0.3324950274579866\n",
      "488 flat images and 512 non-flat images in test set.\n",
      "[[1280  208]\n",
      " [ 218 1294]]\n",
      "Training Accuracy: 85.8 %\n",
      "[[442  70]\n",
      " [ 81 407]]\n",
      "Testing Accuracy: 84.9 %\n",
      "Run 11\n",
      "1489 flat images and 1511 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 11 iterations: 0.03002643585205078\n",
      "Best weights after iteration 10 with a cost of 0.3159407481983644\n",
      "511 flat images and 489 non-flat images in test set.\n",
      "[[1335  176]\n",
      " [ 232 1257]]\n",
      "Training Accuracy: 86.4 %\n",
      "[[407  82]\n",
      " [ 91 420]]\n",
      "Testing Accuracy: 82.7 %\n",
      "Run 12\n",
      "1505 flat images and 1495 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 30 iterations: 0.08807969093322754\n",
      "Best weights after iteration 29 with a cost of 0.3248961798217422\n",
      "495 flat images and 505 non-flat images in test set.\n",
      "[[1290  205]\n",
      " [ 238 1267]]\n",
      "Training Accuracy: 85.23333333333333 %\n",
      "[[434  71]\n",
      " [ 70 425]]\n",
      "Testing Accuracy: 85.9 %\n",
      "Run 13\n",
      "1499 flat images and 1501 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 61 iterations: 0.13312029838562012\n",
      "Best weights after iteration 60 with a cost of 0.3212598440673106\n",
      "501 flat images and 499 non-flat images in test set.\n",
      "[[1338  163]\n",
      " [ 263 1236]]\n",
      "Training Accuracy: 85.8 %\n",
      "[[433  66]\n",
      " [ 95 406]]\n",
      "Testing Accuracy: 83.9 %\n",
      "Run 14\n",
      "1507 flat images and 1493 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 32 iterations: 0.06705999374389648\n",
      "Best weights after iteration 7 with a cost of 0.3406369017459142\n",
      "493 flat images and 507 non-flat images in test set.\n",
      "[[1302  191]\n",
      " [ 255 1252]]\n",
      "Training Accuracy: 85.13333333333334 %\n",
      "[[455  52]\n",
      " [ 87 406]]\n",
      "Testing Accuracy: 86.1 %\n",
      "Run 15\n",
      "1490 flat images and 1510 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 38 iterations: 0.09708786010742188\n",
      "Best weights after iteration 32 with a cost of 0.33091177788219583\n",
      "510 flat images and 490 non-flat images in test set.\n",
      "[[1296  214]\n",
      " [ 231 1259]]\n",
      "Training Accuracy: 85.16666666666667 %\n",
      "[[433  57]\n",
      " [ 80 430]]\n",
      "Testing Accuracy: 86.3 %\n",
      "Run 16\n",
      "1514 flat images and 1486 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 56 iterations: 0.15323615074157715\n",
      "Best weights after iteration 55 with a cost of 0.33517832684731663\n",
      "486 flat images and 514 non-flat images in test set.\n",
      "[[1294  192]\n",
      " [ 243 1271]]\n",
      "Training Accuracy: 85.5 %\n",
      "[[451  63]\n",
      " [ 84 402]]\n",
      "Testing Accuracy: 85.3 %\n",
      "Run 17\n",
      "1478 flat images and 1522 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0010008811950683594\n",
      "Total execution for 52 iterations: 0.15213847160339355\n",
      "Best weights after iteration 51 with a cost of 0.33091532800954815\n",
      "522 flat images and 478 non-flat images in test set.\n",
      "[[1343  179]\n",
      " [ 254 1224]]\n",
      "Training Accuracy: 85.56666666666666 %\n",
      "[[418  60]\n",
      " [ 92 430]]\n",
      "Testing Accuracy: 84.8 %\n",
      "Run 18\n",
      "1506 flat images and 1494 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 31 iterations: 0.0840766429901123\n",
      "Best weights after iteration 4 with a cost of 0.33717496254021406\n",
      "494 flat images and 506 non-flat images in test set.\n",
      "[[1281  213]\n",
      " [ 240 1266]]\n",
      "Training Accuracy: 84.9 %\n",
      "[[441  65]\n",
      " [ 63 431]]\n",
      "Testing Accuracy: 87.2 %\n",
      "Run 19\n",
      "1509 flat images and 1491 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0009999275207519531\n",
      "Total execution for 29 iterations: 0.08507609367370605\n",
      "Best weights after iteration 15 with a cost of 0.3316499336882391\n",
      "491 flat images and 509 non-flat images in test set.\n",
      "[[1289  202]\n",
      " [ 238 1271]]\n",
      "Training Accuracy: 85.33333333333333 %\n",
      "[[441  68]\n",
      " [ 76 415]]\n",
      "Testing Accuracy: 85.6 %\n",
      "Run 20\n",
      "1502 flat images and 1498 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 8 iterations: 0.027023792266845703\n",
      "Best weights after iteration 5 with a cost of 0.33645088855682753\n",
      "498 flat images and 502 non-flat images in test set.\n",
      "[[1291  207]\n",
      " [ 255 1247]]\n",
      "Training Accuracy: 84.6 %\n",
      "[[444  58]\n",
      " [ 61 437]]\n",
      "Testing Accuracy: 88.1 %\n",
      "Run 21\n",
      "1502 flat images and 1498 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 17 iterations: 0.050045013427734375\n",
      "Best weights after iteration 4 with a cost of 0.3388525560185048\n",
      "498 flat images and 502 non-flat images in test set.\n",
      "[[1305  193]\n",
      " [ 261 1241]]\n",
      "Training Accuracy: 84.86666666666666 %\n",
      "[[451  51]\n",
      " [ 80 418]]\n",
      "Testing Accuracy: 86.9 %\n",
      "Run 22\n",
      "1507 flat images and 1493 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 30 iterations: 0.08007240295410156\n",
      "Best weights after iteration 29 with a cost of 0.32840888499177856\n",
      "493 flat images and 507 non-flat images in test set.\n",
      "[[1323  170]\n",
      " [ 262 1245]]\n",
      "Training Accuracy: 85.6 %\n",
      "[[432  75]\n",
      " [ 77 416]]\n",
      "Testing Accuracy: 84.8 %\n",
      "Run 23\n",
      "1513 flat images and 1487 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 56 iterations: 0.18416786193847656\n",
      "Best weights after iteration 5 with a cost of 0.3285221695582275\n",
      "487 flat images and 513 non-flat images in test set.\n",
      "[[1281  206]\n",
      " [ 239 1274]]\n",
      "Training Accuracy: 85.16666666666667 %\n",
      "[[449  64]\n",
      " [ 74 413]]\n",
      "Testing Accuracy: 86.2 %\n",
      "Run 24\n",
      "1492 flat images and 1508 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 13 iterations: 0.03803372383117676\n",
      "Best weights after iteration 7 with a cost of 0.32307780242004314\n",
      "508 flat images and 492 non-flat images in test set.\n",
      "[[1338  170]\n",
      " [ 265 1227]]\n",
      "Training Accuracy: 85.5 %\n",
      "[[429  63]\n",
      " [ 91 417]]\n",
      "Testing Accuracy: 84.6 %\n",
      "Run 25\n",
      "1475 flat images and 1525 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 50 iterations: 0.16414809226989746\n",
      "Best weights after iteration 49 with a cost of 0.34515624429457953\n",
      "525 flat images and 475 non-flat images in test set.\n",
      "[[1332  193]\n",
      " [ 259 1216]]\n",
      "Training Accuracy: 84.93333333333334 %\n",
      "[[418  57]\n",
      " [ 71 454]]\n",
      "Testing Accuracy: 87.2 %\n",
      "Run 26\n",
      "1510 flat images and 1490 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 28 iterations: 0.07506799697875977\n",
      "Best weights after iteration 9 with a cost of 0.3243735781467003\n",
      "490 flat images and 510 non-flat images in test set.\n",
      "[[1308  182]\n",
      " [ 241 1269]]\n",
      "Training Accuracy: 85.9 %\n",
      "[[452  58]\n",
      " [104 386]]\n",
      "Testing Accuracy: 83.8 %\n",
      "Run 27\n",
      "1512 flat images and 1488 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 8 iterations: 0.024021387100219727\n",
      "Best weights after iteration 7 with a cost of 0.32031530851482604\n",
      "488 flat images and 512 non-flat images in test set.\n",
      "[[1323  165]\n",
      " [ 264 1248]]\n",
      "Training Accuracy: 85.7 %\n",
      "[[446  66]\n",
      " [ 92 396]]\n",
      "Testing Accuracy: 84.2 %\n",
      "Run 28\n",
      "1513 flat images and 1487 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0010006427764892578\n",
      "Total execution for 16 iterations: 0.0470423698425293\n",
      "Best weights after iteration 14 with a cost of 0.33493537448485067\n",
      "487 flat images and 513 non-flat images in test set.\n",
      "[[1305  182]\n",
      " [ 264 1249]]\n",
      "Training Accuracy: 85.13333333333334 %\n",
      "[[451  62]\n",
      " [ 77 410]]\n",
      "Testing Accuracy: 86.1 %\n",
      "Run 29\n",
      "1511 flat images and 1489 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0010004043579101562\n",
      "Total execution for 27 iterations: 0.07306599617004395\n",
      "Best weights after iteration 4 with a cost of 0.33244927548529435\n",
      "489 flat images and 511 non-flat images in test set.\n",
      "[[1309  180]\n",
      " [ 251 1260]]\n",
      "Training Accuracy: 85.63333333333334 %\n",
      "[[444  67]\n",
      " [ 85 404]]\n",
      "Testing Accuracy: 84.8 %\n",
      "Run 30\n",
      "1495 flat images and 1505 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 16 iterations: 0.04103732109069824\n",
      "Best weights after iteration 4 with a cost of 0.33760903659514213\n",
      "505 flat images and 495 non-flat images in test set.\n",
      "[[1340  165]\n",
      " [ 282 1213]]\n",
      "Training Accuracy: 85.1 %\n",
      "[[442  53]\n",
      " [ 85 420]]\n",
      "Testing Accuracy: 86.2 %\n",
      "Run 31\n",
      "1488 flat images and 1512 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 22 iterations: 0.06806159019470215\n",
      "Best weights after iteration 21 with a cost of 0.32048524793593125\n",
      "512 flat images and 488 non-flat images in test set.\n",
      "[[1348  164]\n",
      " [ 257 1231]]\n",
      "Training Accuracy: 85.96666666666667 %\n",
      "[[428  60]\n",
      " [104 408]]\n",
      "Testing Accuracy: 83.6 %\n",
      "Run 32\n",
      "1501 flat images and 1499 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 15 iterations: 0.052047014236450195\n",
      "Best weights after iteration 14 with a cost of 0.33854740134045463\n",
      "499 flat images and 501 non-flat images in test set.\n",
      "[[1292  207]\n",
      " [ 239 1262]]\n",
      "Training Accuracy: 85.13333333333334 %\n",
      "[[437  64]\n",
      " [ 71 428]]\n",
      "Testing Accuracy: 86.5 %\n",
      "Run 33\n",
      "1520 flat images and 1480 non-flat images in training set.\n",
      "Iteration: 0\n",
      "Cost: 0.6931471785599431\n",
      "Execution time: 0.0\n",
      "Total execution for 29 iterations: 0.07807016372680664\n",
      "Best weights after iteration 4 with a cost of 0.3312296602808417\n",
      "480 flat images and 520 non-flat images in test set.\n",
      "[[1302  178]\n",
      " [ 267 1253]]\n",
      "Training Accuracy: 85.16666666666667 %\n",
      "[[465  55]\n",
      " [ 89 391]]\n",
      "Testing Accuracy: 85.6 %\n",
      "Run 34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6780/3282694393.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    454\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    455\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'__main__'\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Python convention for ensuring recursive calling of main function does not occur\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 456\u001B[1;33m     \u001B[0mmain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6780/3282694393.py\u001B[0m in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mrun\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mruns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Each run is an independent evaluation of performance\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    398\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Run'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrun\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 399\u001B[1;33m         \u001B[0mdataset\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDataLoader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset_path\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Creating an instance of the dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    400\u001B[0m         \u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msamples\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Randomizing the order of the dataset to ensure order invariance\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    401\u001B[0m         \u001B[0mtrain_test_split\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0.75\u001B[0m  \u001B[1;31m# We selected a 75% training 25% testing for the model training and evaluation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6780/3282694393.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, path)\u001B[0m\n\u001B[0;32m     32\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msamples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m# List to hold the dataset samples\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcalculated_features\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m# List to hold the calculated features that will be used as input to the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Begin data loading method\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mload_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6780/3282694393.py\u001B[0m in \u001B[0;36mload_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     39\u001B[0m         \u001B[1;31m# index = 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mfile\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfiles\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Iterate over all files in the dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m             \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'L'\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Open the greyscale images, specifying 'L' to ensure correct loading\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m             \"\"\"\n",
      "\u001B[1;32m~\\Desktop\\PyCharm Projects\\engr_518_group7_course_project\\2D Classifier\\venv\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   2973\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2974\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mfilename\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2975\u001B[1;33m         \u001B[0mfp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuiltins\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"rb\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2976\u001B[0m         \u001B[0mexclusive_fp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2977\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Group Number: 2\n",
    "Team members: Matthew Tucsok, Aliakbar Davoodi, Don Milinda Thilan Sangapalaarachchi, Sydney Agbonkhese\n",
    "Project Title: UAV Landing: Flat Ground Detection\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    This class manages how images are loaded in, preprocessed, and assembled into an input format compatible with our\n",
    "    2D classifier model. Note that due to how we create our training and test sets, both sets get preprocessed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Initializing the data loader to find the dataset images.\n",
    "        :param path: Path to the root of the program. The root should contain the executing script, and a folder\n",
    "        named \"Greyscale Dataset\" in it which contains the 4000 images in the dataset. Note that the above jupyter\n",
    "        cell should auto-unzip and extract the dataset to the correct location.\n",
    "        \"\"\"\n",
    "        self.source = path\n",
    "        self.samples = []  # List to hold the dataset samples\n",
    "        self.calculated_features = []  # List to hold the calculated features that will be used as input to the model\n",
    "        self.load_data()  # Begin data loading method\n",
    "\n",
    "    def load_data(self):\n",
    "        files = glob.glob(self.source + '/*.png')  # This will put all the .png filenames into a list\n",
    "\n",
    "        # index = 0\n",
    "        for file in files:  # Iterate over all files in the dataset\n",
    "            img = Image.open(file).convert('L')  # Open the greyscale images, specifying 'L' to ensure correct loading\n",
    "\n",
    "            \"\"\"\n",
    "            The following 3 line were for visualization purposes only in the report. They select a specific image to\n",
    "            show how the original greyscale image looks before pre-processing.\n",
    "            \"\"\"\n",
    "            # grey = Image.open(file).convert('L')\n",
    "            # if index % 3334 == 0 and index > 0:\n",
    "            #     img.show()\n",
    "\n",
    "            \"\"\"\n",
    "            # img_h is a histogram with 256 bins with each bin n counting how many times a pixel with a value of n\n",
    "            appears in the image.\n",
    "            \"\"\"\n",
    "            img_h = np.array(img.histogram())\n",
    "            var = np.var(img_h)  # Calculating the variance of the histogram. This is one of our final features\n",
    "\n",
    "            \"\"\"\n",
    "            img.filter(ImageFilter.FIND_EDGES) generates an edge-detected image with the same dimensions as the original\n",
    "            greyscale image.\n",
    "            \"\"\"\n",
    "            img = img.filter(ImageFilter.FIND_EDGES)\n",
    "\n",
    "            # The following 2 lines were for showing the edge-detected image for the report\n",
    "            # if index % 3334 == 0 and index > 0:\n",
    "            #     img.show()\n",
    "\n",
    "            img_array = np.array(img)  # Ensuring PIL image is now a numpy array\n",
    "\n",
    "            # Calculating the mean of the edge-detected image\n",
    "            mean = np.sum(img_array) / (img_array.shape[0] * img_array.shape[1])\n",
    "\n",
    "            binary_img = np.where(img_array > mean, 1, 0)  # Thresholding edge-detected image based on mean pixel value\n",
    "            edge_pixel_sum = np.sum(\n",
    "                binary_img)  # Summing all of the pixel values in the binary image. 2nd final feature\n",
    "\n",
    "            # Following 4 lines used to display the binary image for visualization in the report.\n",
    "            # if index % 3334 == 0 and index > 0:\n",
    "            #     print(index)\n",
    "            #     pil_binary_img = Image.fromarray(binary_img*255)\n",
    "            #     pil_binary_img.show()\n",
    "            file = file.replace('\\\\','/')  # Replacing backslashes with forward slashes for consistency on different OS\n",
    "            splits = file.split('/')  # Parsing the file name for label extraction. Works on browser jupyter notebook\n",
    "\n",
    "            class_and_index = splits[-1]  # Getting the last split which contain the name of the image with filetype\n",
    "            label_name, _ = class_and_index.split('_', 2)  # Getting only the 'f' or 'nf' part of the image name\n",
    "            label = None\n",
    "            if label_name == 'f':\n",
    "                label = 1  # Flat images are class 1\n",
    "            elif label_name == 'nf':\n",
    "                label = 0  # Non-flat images are class 0\n",
    "            else:\n",
    "                raise SyntaxError('Invalid class label detected')  # Just a check to see if data was loaded correctly\n",
    "            self.calculated_features.append(\n",
    "                np.array([var, edge_pixel_sum]))  # Appending the features to the feature list\n",
    "            # self.samples.append([img, label])  # (Deprecated)\n",
    "            self.samples.append([binary_img, label])\n",
    "            # self.samples.append([grey, label])\n",
    "            # index += 1\n",
    "\n",
    "        \"\"\"\n",
    "        The following block of code is where the final feature vector is generated as input to the model. This section\n",
    "        contains commented code and visibly redundant lines to keep above code consistent for all iterations of input\n",
    "        while still maintaining functionality. For example, in the final feature vector we do not include image pixels,\n",
    "        so vectorization of the image is no longer required and therefore replaced with an empty array to remove these\n",
    "        features\n",
    "        \"\"\"\n",
    "        index = 0\n",
    "        for sample in self.samples:  # Iterating over all samples in the dataset\n",
    "            img_array = np.array(sample[0])  # (Deprecated) Extracting the previous image associated with a sample\n",
    "            img_vector = img_array.ravel()  # (Deprecated) vectorizing the 64 x 64 image to a 4096 x 1 vector\n",
    "            img_vector = np.array(\n",
    "                [])  # Removing the image vector as it was not used in the final iteration of the model\n",
    "\n",
    "            # (Deprecated) Used to remove calculated features to test only the performance of vectorized image inputs\n",
    "            # self.calculated_features[index] = np.array([])\n",
    "\n",
    "            # The line below will keep whatever features still exist after the decisions made above\n",
    "            sample_vector = np.hstack((img_vector, self.calculated_features[index]))\n",
    "            self.samples[index][0] = sample_vector\n",
    "            index += 1\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def sigmoid(t):\n",
    "    \"\"\"\n",
    "    The sigmoid activation function. This predicts the label of a sample point x. The jit decorator is for performance\n",
    "    purposes and allows for simple parallel CPU computation\n",
    "\n",
    "    :param t: x_bar dot multiplied with the weights vector\n",
    "    :return: prediction of the class for sample x\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def regularized_cross_entropy_cost(y, weights, preds, lam, log_eps=1e-9):\n",
    "    \"\"\"\n",
    "    This function calculated the regularized cross entropy cost.\n",
    "\n",
    "    :param y:\n",
    "    :param weights: (deprecated field to maintain code clarity)\n",
    "    :param preds: label prediction of x generated by sigmoid\n",
    "    :param lam: regularization parameter\n",
    "    :param log_eps: small value to avoid negative log bugs\n",
    "    :return: regularized cross entropy cost\n",
    "    \"\"\"\n",
    "    return -1 / (len(y)) * np.sum(y * np.log(preds + log_eps) + (1 - y) * np.log(\n",
    "        1 - preds + log_eps))\n",
    "\n",
    "\n",
    "def find_gradient_numerically(weights, x_bar, y, eps, lam):\n",
    "    \"\"\"\n",
    "    (Deprecated) This function uses the definition of the derivative to find the gradient with respect to each weight. It first\n",
    "    calculated the cost with the original weights vector, then sequential increments one of the weights by epsilon,\n",
    "    recalculates the cost, finds the derivative, then decrements that same weight by epsilon. This step is repeated for\n",
    "    each weight in the weights vector to find the entire gradient vector.\n",
    "\n",
    "    :param weights: weights vector for the model\n",
    "    :param x_bar: x feature vector front-padded with a bias feature of 1\n",
    "    :param y: label of sample x\n",
    "    :param eps: small step for numerically calculating the derivative using the definition of a derivative\n",
    "    :param lam: cross entropy regularization parameter\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    gradients = []  # List to hold each element of the gradient\n",
    "    preds = sigmoid(np.dot(x_bar, weights))  # Calculating class prediction for x\n",
    "    fx = regularized_cross_entropy_cost(y, weights, preds,\n",
    "                                        lam)  # The cost function value before taking a step. This is constant for calculating all gradients in a given weights vector\n",
    "    temp_weights = weights.copy()  # Creating a copy of weights vector to reduce calculations\n",
    "    for weight in range(len(weights)):  # Loop to iterate over each weight\n",
    "        temp_weights[weight] += eps  # Adding the small epsilon value to one of the weights\n",
    "        preds = sigmoid(np.dot(x_bar, temp_weights))  # Predicting class for the updated cost\n",
    "        fx_plus_eps = regularized_cross_entropy_cost(y, temp_weights, preds,\n",
    "                                                     lam)  # Finding the new cost after small step\n",
    "        gradients.append((fx_plus_eps - fx) / eps)  # Definition of a derivative (rise/run)\n",
    "        temp_weights[weight] -= eps  # Decrementing the weight by epsilon\n",
    "    return np.array(gradients)\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def find_fast_gradient_numerically(weights, x_bar, y, eps, lam):\n",
    "    \"\"\"\n",
    "    (Deprecated) See \"find_gradient_numerically\" above for detailed description of numerical method for finding the\n",
    "    gradient. This function is identical in operation, with the exception that any function calls within the for\n",
    "    loop have been refactored so the code from those functions is directly in the loop. This is a requirement for jit,\n",
    "    a just-in-time compilation tool for significantly increasing speed by compiling to machine code after the first\n",
    "    iteration of the loop. This function is roughly 10x faster than the non-jit numerical gradient function above.\n",
    "    \"\"\"\n",
    "    log_eps = 1e-9\n",
    "    gradients = []\n",
    "    preds = 1 / (1 + np.exp(-(np.dot(x_bar, weights))))\n",
    "    fx = regularized_cross_entropy_cost(y, weights, preds, lam)\n",
    "    temp_weights = weights.copy()\n",
    "    for weight in range(weights.shape[0]):\n",
    "        temp_weights[weight] += eps\n",
    "        preds = 1 / (1 + np.exp(-(np.dot(x_bar, temp_weights))))\n",
    "        fx_plus_eps = -1 / (y.shape[0]) * np.sum(\n",
    "            y * np.log(preds + log_eps) + (1 - y) * np.log(1 - preds + log_eps) + lam * np.linalg.norm(weights[1:]))\n",
    "        gradients.append((fx_plus_eps - fx) / eps)\n",
    "        temp_weights[weight] -= eps\n",
    "    return np.array(gradients)\n",
    "\n",
    "\n",
    "def find_closed_form_gradient(weights, x_bar, y, eps, lam):\n",
    "    \"\"\"\n",
    "    Closed form for finding the gradient of the cross entropy cost function. This is the fastest gradient method by far\n",
    "    for calculating the gradient as it is one step. For comparison, the \"find_fast_gradient_numerically\" takes 6 hours\n",
    "    to run 4300 iterations of training, while this method only takes roughly a minute for the same 4300 iterations.\n",
    "\n",
    "    :param weights: weights vectors\n",
    "    :param x_bar: x feature vector front-padded with a 1 bias\n",
    "    :param y: label for the given sample x\n",
    "    :param eps: (deprecated)\n",
    "    :param lam: (Deprecated) At this point in development we found that the regularization parameter was not helping our\n",
    "    model learn, so it is not required. We keep it as a field to reduce complexity of which parameters we are passing\n",
    "    :return: Gradient of cross-entropy cost function\n",
    "    \"\"\"\n",
    "    gradients = (-1 / y.shape[0]) * np.matmul(x_bar.T, y - sigmoid(np.matmul(x_bar, weights)))\n",
    "    return np.array(gradients)\n",
    "\n",
    "\n",
    "class Model:\n",
    "    \"\"\"\n",
    "    Our 2D perceptron classifier (i.e. single neuron classifier). Within this class is the initialization of the model,\n",
    "    the gradient descent algorithm, and accuracy calculation via a from-scratch confusion matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, samples, learning_rate=0.001, epsilon=1e-7, batch_size=32):\n",
    "        \"\"\"\n",
    "        Initialization of the model with training samples, then perform gradient descent.\n",
    "\n",
    "        :param samples: A tuple of training samples with contains the feature vector (min 2 features due to a bug) and\n",
    "        the labels of the samples\n",
    "        :param learning_rate: alpha, or step size for gradient descent. Best value empirically determined to be 0.001\n",
    "        :param epsilon: The small step for calculating the gradient of the cost function numerically. Best value\n",
    "        empirically determined to be 1e-7\n",
    "        :param batch_size: mini-batch size. Best value empirically determined to be 32\n",
    "        \"\"\"\n",
    "\n",
    "        self.x, self.y = zip(*samples)  # Splitting the feature vectors and the labels of the samples\n",
    "\n",
    "        \"\"\"\n",
    "        self.x: An m x n matrix where m is the number of samples in the training set and n is the number of features\n",
    "        in the sample.\n",
    "        \"\"\"\n",
    "        self.x = np.array(self.x)\n",
    "\n",
    "        self.y = np.array(self.y)  # An m x 1 vector where m is the number of samples in the training set.\n",
    "        num_samples = len(self.y)  # Number of samples in the dataset\n",
    "        self.x_bar = np.hstack((np.ones([num_samples, 1]), self.x))  # Front-padding ones column to x matrix\n",
    "        self.weights = np.zeros([self.x_bar.shape[1]])  # Initializing weights vector to 0 with a bias weight as well\n",
    "\n",
    "        \"\"\"\n",
    "         After many experiments we decided to omit the lambda regularization parameter for the regularized cross-entropy\n",
    "         cost function as it was reducing test accuracy. Thus we set it to 0.\n",
    "        \"\"\"\n",
    "        self.lam = 0\n",
    "\n",
    "        self.eps = epsilon\n",
    "        self.alpha = learning_rate\n",
    "\n",
    "        self.iterations = 100000  # Choosing large maximum of iterations since the code runs quite fast. Never hits this.\n",
    "        self.stop_criterion = 1e-5  # Found to be a good stopping criterion for test accuracy and speed\n",
    "        self.iteration_display = 100  # How often to display how training is performing. Too small will lag code\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        \"\"\"\n",
    "        The following lines handle the creation of mini-batches. Note that if the batch size does not divide evenly into\n",
    "        the size of the dataset, up to \"batch_size\" samples will be rejected from training due to the remainder after\n",
    "        division.\n",
    "        \"\"\"\n",
    "        self.num_batches = int(num_samples / self.batch_size)  # Finding how many batches there will be in training\n",
    "        total_rows = self.num_batches * self.batch_size  # Total number of samples to keep for mini-batch training\n",
    "        temp_x_bar = self.x_bar[:total_rows, :].copy()  # Keeping the calculated number of samples\n",
    "        temp_y = self.y[:total_rows].copy()  # Keeping the corresponding number of labels\n",
    "        self.x_bar_batches = np.split(temp_x_bar, self.num_batches,\n",
    "                                      axis=0)  # Splitting samples evenly into mini-batches\n",
    "        self.y_batches = np.split(temp_y, self.num_batches, axis=0)  # Splitting labels evenly into mini-batches\n",
    "\n",
    "        self.gradient_descent()  # Perform gradient descent\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        \"\"\"\n",
    "        Performing the mini-batch adaptive step size gradient descent using a closed-form gradient of the cross-entropy\n",
    "        cost function.\n",
    "        :return: No explicit return value, but the instance of the class will set its weights to those corresponding to the lowest cost\n",
    "        found during training.\n",
    "        \"\"\"\n",
    "\n",
    "        total_start = time.time()  # Storing start time to determine total execution time of the gradient descent algo\n",
    "        start = time.time()  # Intermediate start time for display purposes\n",
    "        history = []  # List for storing the weights and cost histories\n",
    "\n",
    "        # Loop for iteratively finding the gradients of the cost function to convergence\n",
    "        for i in range(self.iterations):\n",
    "\n",
    "            \"\"\"\n",
    "            The following two lines are performed to both visualize how training is going after iterating over all\n",
    "            mini-batches in an complete descent iteration. This cost is appended to the history after each complete\n",
    "            descent iteration.\n",
    "            \"\"\"\n",
    "            preds = sigmoid(np.dot(self.x_bar, self.weights))  # Using sigmoid to predict sample classes\n",
    "            cost = regularized_cross_entropy_cost(self.y, self.weights, preds, self.lam)  # Cost of full batch\n",
    "\n",
    "            # For visualization purposes only. How the training is performing after \"self.iteration_display\" iterations.\n",
    "            if i % self.iteration_display == 0:\n",
    "                end = time.time()\n",
    "                duration = end - start\n",
    "                print('Iteration:', i)\n",
    "                print('Cost:', cost)\n",
    "                print('Execution time:', duration)\n",
    "                start = time.time()\n",
    "\n",
    "            for batch in range(self.num_batches):  # Iterating over each mini-batch\n",
    "                gradient = find_closed_form_gradient(self.weights, self.x_bar_batches[batch],\n",
    "                                                     self.y_batches[batch],\n",
    "                                                     self.eps,\n",
    "                                                     self.lam)  # Finding the gradient for a given mini-batch\n",
    "                gradient_norm = np.linalg.norm(gradient)  # Taking the L2-norm of the gradient\n",
    "\n",
    "                \"\"\"\n",
    "                Updating the weights for the model. Note the division by (i + 1) is the adaptive step size, which\n",
    "                decreases the step size as the training continues.\n",
    "                \"\"\"\n",
    "                self.weights -= self.alpha / (i + 1) * gradient / gradient_norm\n",
    "\n",
    "            history.append((cost, self.weights, i))  # After running through all mini-batches, save the cost and weights\n",
    "\n",
    "            if i > 0:  # Making sure at least 2 iterations have occurred before calculating stop criterion\n",
    "\n",
    "                # Absolute difference check between current and previous iteration to see if stop criteria is met\n",
    "                if np.abs(history[i][0] - history[i - 1][0]) < self.stop_criterion:\n",
    "                    break\n",
    "\n",
    "        print('Total execution for', len(history), 'iterations:', time.time() - total_start)\n",
    "\n",
    "        # Following lines for plotting purposes. Uncomment to see plot of cost vs iteration, but not recommended.\n",
    "        # costs, weights, indices = zip(*history)\n",
    "        # plt.plot(range(len(history)), costs)\n",
    "        # plt.xlabel('Iteration')\n",
    "        # plt.ylabel('Cost')\n",
    "        # plt.title('Cost vs Iterations')\n",
    "        # plt.show()\n",
    "\n",
    "        history.sort(key=lambda tup: tup[0])  # Sorting the history by cost to see which cost is lowest\n",
    "        print('Best weights after iteration', history[0][2], 'with a cost of', history[0][0])\n",
    "        self.weights = history[0][1]  # Finalizing the internally stored weights of the model\n",
    "        x = 1\n",
    "\n",
    "    def accuracy(self, test_samples):\n",
    "        \"\"\"\n",
    "        Method for measuring the model accuracy on a set of samples.\n",
    "        :param test_samples: A tuple of test feature vectors and label vector\n",
    "        :return: 2 x 2 confusion matrix, where rows corresponds to the true class of a sample and the columns correspond\n",
    "        to the predicted class of a sample.\n",
    "        \"\"\"\n",
    "        x_tests, y_tests = zip(*test_samples)  # Splitting the feature vectors from the label vector\n",
    "        x_bar_tests = np.hstack((np.ones([len(y_tests), 1]), x_tests))  # Front padding feature vectors with a 1\n",
    "        predictions = sigmoid(np.dot(x_bar_tests, self.weights))  # Predicting the labels of the input feature vectors\n",
    "        return Model.confusion_matrix(y_tests, predictions)\n",
    "\n",
    "    @staticmethod\n",
    "    def confusion_matrix(actuals, predictions):\n",
    "        \"\"\"\n",
    "        Function for generating the 2 x 2 confusion matrix.\n",
    "        :param actuals: Vector of actual labels for a set of samples.\n",
    "        :param predictions: Vector of label predictions for a set of samples.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        thresh = predictions.round()  # Rounding predicted label, i.e. thresholding by 0.5 to get either 0 or 1\n",
    "        c11 = np.sum(np.logical_not(np.logical_or(actuals, thresh)))  # Finding true predictions of class 0\n",
    "        c12 = np.sum(np.logical_and(np.logical_not(actuals), thresh))  # Finding false positives of class 0\n",
    "        c21 = np.sum(np.logical_and(actuals, np.logical_not(thresh)))  # Finding false positives of class 1\n",
    "        c22 = np.sum(np.logical_and(actuals, thresh))  # Finding true predictions of class 1\n",
    "        matrix = np.array([[c11, c12], [c21, c22]])  # Assembling the confusion matrix\n",
    "        return matrix\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    The main executing function. This function is responsible for finding the path to our dataset, creating an instance\n",
    "    of our dataset, creating an instance of our model, and running the cross-validation of our model.\n",
    "    \"\"\"\n",
    "    notebook_path = os.path.abspath(\"ENGR_518_group_2.ipynb\")\n",
    "    dataset_path = os.path.join(os.path.dirname(notebook_path), \"Greyscale Dataset\")\n",
    "\n",
    "    \"\"\"\n",
    "    # \"runs\" controls how many times the model is trained and tested. This should be performed multiple times for\n",
    "    evaluating model accuracy since the training and testing sets are randomly generated with a roughly 50/50 split of\n",
    "    non-flat and flat images in each set. This ensemble cross-validation method of evaluation uses the law of large\n",
    "    numbers to find the true general accuracy of the final model.\n",
    "    \"\"\"\n",
    "    runs = 100  # Large enough that average accuracy will have a decent confidence based on variance of model\n",
    "    accuracies = []  # List to store test accuracies for cross validation\n",
    "    start = time.time()  # Start time for timing the total execution of the multiple runs of the program\n",
    "    for run in range(runs):  # Each run is an independent evaluation of performance\n",
    "        print('Run', run + 1)\n",
    "        dataset = DataLoader(dataset_path)  # Creating an instance of the dataset\n",
    "        random.shuffle(dataset.samples)  # Randomizing the order of the dataset to ensure order invariance\n",
    "        train_test_split = 0.75  # We selected a 75% training 25% testing for the model training and evaluation\n",
    "        split_index = round(len(dataset.samples) * train_test_split)  # Determining where to split the dataset\n",
    "        training_set = dataset.samples[:split_index]  # Extracting the training set from the shuffled dataset\n",
    "        test_set = dataset.samples[split_index:]  # Extracting the testing set from the shuffled dataset\n",
    "\n",
    "        \"\"\"\n",
    "        The following block of code is for visualizing how many images are flat and how many are non-flat for a training\n",
    "        set. This was to see if the model is biased towards the class with more examples. This did not seem to be too\n",
    "        much of a problem in testing.\n",
    "        \"\"\"\n",
    "        flat_label_count = 0\n",
    "        not_flat_label_count = 0\n",
    "        for sample in training_set:\n",
    "            if sample[1] == 1:\n",
    "                flat_label_count += 1\n",
    "            else:\n",
    "                not_flat_label_count += 1\n",
    "        print(flat_label_count, 'flat images and', not_flat_label_count, 'non-flat images in training set.')\n",
    "\n",
    "        classifier = Model(training_set)  # Creating an instance of the classifier. This initiates model training.\n",
    "\n",
    "        \"\"\"\n",
    "        Code block below checks the number of flat and non-flat images in the test set.\n",
    "        \"\"\"\n",
    "        flat_label_count = 0\n",
    "        not_flat_label_count = 0\n",
    "        for sample in test_set:\n",
    "            if sample[1] == 1:\n",
    "                flat_label_count += 1\n",
    "            else:\n",
    "                not_flat_label_count += 1\n",
    "        print(flat_label_count, 'flat images and', not_flat_label_count, 'non-flat images in test set.')\n",
    "\n",
    "        confusion_matrix = classifier.accuracy(training_set)  # Getting the confusion matrix of the training_set\n",
    "        accuracy = 100 * np.trace(confusion_matrix) / np.sum(confusion_matrix)  # Calculating accuracy of training set\n",
    "        print(confusion_matrix)\n",
    "        print('Training Accuracy:', accuracy, '%')\n",
    "\n",
    "        confusion_matrix = classifier.accuracy(test_set)  # Getting the confusion matrix of the test set\n",
    "        print(confusion_matrix)\n",
    "        accuracy = 100 * np.trace(confusion_matrix) / np.sum(confusion_matrix)  # Calculating accuracy of test set\n",
    "        accuracies.append(accuracy)  # Appending only the test accuracy to the list of accuracy for cross-validation\n",
    "        print('Testing Accuracy:', accuracy, '%')\n",
    "\n",
    "    accuracies = np.array(accuracies)  # Converting python list to numpy array for accuracies\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    var_accuracy = np.var(accuracies)  # Variance of accuracies\n",
    "    std_accuracy = np.sqrt(var_accuracy)  # Standard deviation of accuracies\n",
    "    print('Average of Accuracy:', mean_accuracy, '%')\n",
    "    print('Variance of Accuracy:', var_accuracy)\n",
    "    print('Standard Deviation of Accuracy:', std_accuracy)\n",
    "    print('Runtime for', runs, 'runs:', round(time.time() - start, 2), 'seconds')  # Complete runtime for the runs\n",
    "\n",
    "\n",
    "if __name__ == '__main__':  # Python convention for ensuring recursive calling of main function does not occur\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}