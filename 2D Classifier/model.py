import numpy as np
import matplotlib.pyplot as plt
import time
from numba import jit


@jit(nopython=True, parallel=True)
def sigmoid(t):
    """
    The sigmoid activation function. This predicts the label of a sample point x. The jit decorator is for performance
    purposes and allows for simple parallel CPU computation

    :param t: x_bar dot multiplied with the weights vector
    :return: prediction of the class for sample x
    """
    return 1 / (1 + np.exp(-t))


@jit(nopython=True, parallel=True)
def regularized_cross_entropy_cost(y, weights, preds, lam, log_eps=1e-9):
    """
    This function calculated the regularized cross entropy cost.

    :param y:
    :param weights: (deprecated field to maintain code clarity)
    :param preds: label prediction of x generated by sigmoid
    :param lam: regularization parameter
    :param log_eps: small value to avoid negative log bugs
    :return: regularized cross entropy cost
    """
    return -1 / (len(y)) * np.sum(y * np.log(preds + log_eps) + (1 - y) * np.log(
        1 - preds + log_eps))


def find_gradient_numerically(weights, x_bar, y, eps, lam):
    """
    (Deprecated) This function uses the definition of the derivative to find the gradient with respect to each weight. It first
    calculated the cost with the original weights vector, then sequential increments one of the weights by epsilon,
    recalculates the cost, finds the derivative, then decrements that same weight by epsilon. This step is repeated for
    each weight in the weights vector to find the entire gradient vector.

    :param weights: weights vector for the model
    :param x_bar: x feature vector front-padded with a bias feature of 1
    :param y: label of sample x
    :param eps: small step for numerically calculating the derivative using the definition of a derivative
    :param lam: cross entropy regularization parameter
    :return:
    """
    gradients = []  # List to hold each element of the gradient
    preds = sigmoid(np.dot(x_bar, weights))  # Calculating class prediction for x
    fx = regularized_cross_entropy_cost(y, weights, preds,
                                        lam)  # The cost function value before taking a step. This is constant for calculating all gradients in a given weights vector
    temp_weights = weights.copy()  # Creating a copy of weights vector to reduce calculations
    for weight in range(len(weights)):  # Loop to iterate over each weight
        temp_weights[weight] += eps  # Adding the small epsilon value to one of the weights
        preds = sigmoid(np.dot(x_bar, temp_weights))  # Predicting class for the updated cost
        fx_plus_eps = regularized_cross_entropy_cost(y, temp_weights, preds,
                                                     lam)  # Finding the new cost after small step
        gradients.append((fx_plus_eps - fx) / eps)  # Definition of a derivative (rise/run)
        temp_weights[weight] -= eps  # Decrementing the weight by epsilon
    return np.array(gradients)


@jit(nopython=True, parallel=True)
def find_fast_gradient_numerically(weights, x_bar, y, eps, lam):
    """
    (Deprecated) See "find_gradient_numerically" above for detailed description of numerical method for finding the
    gradient. This function is identical in operation, with the exception that any function calls within the for
    loop have been refactored so the code from those functions is directly in the loop. This is a requirement for jit,
    a just-in-time compilation tool for significantly increasing speed by compiling to machine code after the first
    iteration of the loop. This function is roughly 10x faster than the non-jit numerical gradient function above.
    """
    log_eps = 1e-9
    gradients = []
    preds = 1 / (1 + np.exp(-(np.dot(x_bar, weights))))
    fx = regularized_cross_entropy_cost(y, weights, preds, lam)
    temp_weights = weights.copy()
    for weight in range(weights.shape[0]):
        temp_weights[weight] += eps
        preds = 1 / (1 + np.exp(-(np.dot(x_bar, temp_weights))))
        fx_plus_eps = -1 / (y.shape[0]) * np.sum(
            y * np.log(preds + log_eps) + (1 - y) * np.log(1 - preds + log_eps) + lam * np.linalg.norm(weights[1:]))
        gradients.append((fx_plus_eps - fx) / eps)
        temp_weights[weight] -= eps
    return np.array(gradients)


def find_closed_form_gradient(weights, x_bar, y, eps, lam):
    """
    Closed form for finding the gradient of the cross entropy cost function. This is the fastest gradient method by far
    for calculating the gradient as it is one step. For comparison, the "find_fast_gradient_numerically" takes 6 hours
    to run 4300 iterations of training, while this method only takes roughly a minute for the same 4300 iterations.

    :param weights: weights vectors
    :param x_bar: x feature vector front-padded with a 1 bias
    :param y: label for the given sample x
    :param eps: (deprecated)
    :param lam: (Deprecated) At this point in development we found that the regularization parameter was not helping our
    model learn, so it is not required. We keep it as a field to reduce complexity of which parameters we are passing
    :return: Gradient of cross-entropy cost function
    """
    gradients = (-1 / y.shape[0]) * np.matmul(x_bar.T, y - sigmoid(np.matmul(x_bar, weights)))
    return np.array(gradients)


class Model:
    """
    Our 2D perceptron classifier (i.e. single neuron classifier). Within this class is the initialization of the model,
    the gradient descent algorithm, and accuracy calculation via a from-scratch confusion matrix.
    """

    def __init__(self, samples, learning_rate=0.001, epsilon=1e-7, batch_size=32):
        """
        Initialization of the model with training samples, then perform gradient descent.

        :param samples: A tuple of training samples with contains the feature vector (min 2 features due to a bug) and
        the labels of the samples
        :param learning_rate: alpha, or step size for gradient descent. Best value empirically determined to be 0.001
        :param epsilon: The small step for calculating the gradient of the cost function numerically. Best value
        empirically determined to be 1e-7
        :param batch_size: mini-batch size. Best value empirically determined to be 32
        """

        self.x, self.y = zip(*samples)  # Splitting the feature vectors and the labels of the samples

        """
        self.x: An m x n matrix where m is the number of samples in the training set and n is the number of features 
        in the sample.
        """
        self.x = np.array(self.x)

        self.y = np.array(self.y)  # An m x 1 vector where m is the number of samples in the training set.
        num_samples = len(self.y)  # Number of samples in the dataset
        self.x_bar = np.hstack((np.ones([num_samples, 1]), self.x))  # Front-padding ones column to x matrix
        self.weights = np.zeros([self.x_bar.shape[1]])  # Initializing weights vector to 0 with a bias weight as well

        """
         After many experiments we decided to omit the lambda regularization parameter for the regularized cross-entropy
         cost function as it was reducing test accuracy. Thus we set it to 0. 
        """
        self.lam = 0

        self.eps = epsilon
        self.alpha = learning_rate

        self.iterations = 100000  # Choosing large maximum of iterations since the code runs quite fast. Never hits this.
        self.stop_criterion = 1e-5  # Found to be a good stopping criterion for test accuracy and speed
        self.iteration_display = 100  # How often to display how training is performing. Too small will lag code
        self.batch_size = batch_size

        """
        The following lines handle the creation of mini-batches. Note that if the batch size does not divide evenly into
        the size of the dataset, up to "batch_size" samples will be rejected from training due to the remainder after
        division.
        """
        self.num_batches = int(num_samples / self.batch_size)  # Finding how many batches there will be in training
        total_rows = self.num_batches * self.batch_size  # Total number of samples to keep for mini-batch training
        temp_x_bar = self.x_bar[:total_rows, :].copy()  # Keeping the calculated number of samples
        temp_y = self.y[:total_rows].copy()  # Keeping the corresponding number of labels
        self.x_bar_batches = np.split(temp_x_bar, self.num_batches,
                                      axis=0)  # Splitting samples evenly into mini-batches
        self.y_batches = np.split(temp_y, self.num_batches, axis=0)  # Splitting labels evenly into mini-batches

        self.gradient_descent()  # Perform gradient descent

    def gradient_descent(self):
        """
        Performing the mini-batch adaptive step size gradient descent using a closed-form gradient of the cross-entropy
        cost function.
        :return: No explicit return value, but the instance of the class will set its weights to those corresponding to the lowest cost
        found during training.
        """

        total_start = time.time()  # Storing start time to determine total execution time of the gradient descent algo
        start = time.time()  # Intermediate start time for display purposes
        history = []  # List for storing the weights and cost histories

        # Loop for iteratively finding the gradients of the cost function to convergence
        for i in range(self.iterations):

            """
            The following two lines are performed to both visualize how training is going after iterating over all 
            mini-batches in an complete descent iteration. This cost is appended to the history after each complete 
            descent iteration.
            """
            preds = sigmoid(np.dot(self.x_bar, self.weights))  # Using sigmoid to predict sample classes
            cost = regularized_cross_entropy_cost(self.y, self.weights, preds, self.lam)  # Cost of full batch

            # For visualization purposes only. How the training is performing after "self.iteration_display" iterations.
            if i % self.iteration_display == 0:
                end = time.time()
                duration = end - start
                print('Iteration:', i)
                print('Cost:', cost)
                print('Execution time:', duration)
                start = time.time()

            for batch in range(self.num_batches):  # Iterating over each mini-batch
                gradient = find_closed_form_gradient(self.weights, self.x_bar_batches[batch],
                                                     self.y_batches[batch],
                                                     self.eps,
                                                     self.lam)  # Finding the gradient for a given mini-batch
                gradient_norm = np.linalg.norm(gradient)  # Taking the L2-norm of the gradient

                """
                Updating the weights for the model. Note the division by (i + 1) is the adaptive step size, which
                decreases the step size as the training continues.
                """
                self.weights -= self.alpha / (i + 1) * gradient / gradient_norm

            history.append((cost, self.weights, i))  # After running through all mini-batches, save the cost and weights

            if i > 0:  # Making sure at least 2 iterations have occurred before calculating stop criterion

                # Absolute difference check between current and previous iteration to see if stop criteria is met
                if np.abs(history[i][0] - history[i - 1][0]) < self.stop_criterion:
                    break

        print('Total execution for', len(history), 'iterations:', time.time() - total_start)

        # Following lines for plotting purposes. Uncomment to see plot of cost vs iteration
        # costs, weights, indices = zip(*history)
        # plt.plot(range(len(history)), costs)
        # plt.xlabel('Iteration')
        # plt.ylabel('Cost')
        # plt.title('Cost vs Iterations')
        # plt.show()

        history.sort(key=lambda tup: tup[0])  # Sorting the history by cost to see which cost is lowest
        print('Best weights after iteration', history[0][2], 'with a cost of', history[0][0])
        self.weights = history[0][1]  # Finalizing the internally stored weights of the model
        x = 1

    def accuracy(self, test_samples):
        """
        Method for measuring the model accuracy on a set of samples.
        :param test_samples: A tuple of test feature vectors and label vector
        :return: 2 x 2 confusion matrix, where rows corresponds to the true class of a sample and the columns correspond
        to the predicted class of a sample.
        """
        x_tests, y_tests = zip(*test_samples)  # Splitting the feature vectors from the label vector
        x_bar_tests = np.hstack((np.ones([len(y_tests), 1]), x_tests))  # Front padding feature vectors with a 1
        predictions = sigmoid(np.dot(x_bar_tests, self.weights))  # Predicting the labels of the input feature vectors
        return Model.confusion_matrix(y_tests, predictions)

    @staticmethod
    def confusion_matrix(actuals, predictions):
        """
        Function for generating the 2 x 2 confusion matrix.
        :param actuals: Vector of actual labels for a set of samples.
        :param predictions: Vector of label predictions for a set of samples.
        :return:
        """
        thresh = predictions.round()  # Rounding predicted label, i.e. thresholding by 0.5 to get either 0 or 1
        c11 = np.sum(np.logical_not(np.logical_or(actuals, thresh)))  # Finding true predictions of class 0
        c12 = np.sum(np.logical_and(np.logical_not(actuals), thresh))  # Finding false positives of class 0
        c21 = np.sum(np.logical_and(actuals, np.logical_not(thresh)))  # Finding false positives of class 1
        c22 = np.sum(np.logical_and(actuals, thresh))  # Finding true predictions of class 1
        matrix = np.array([[c11, c12], [c21, c22]])  # Assembling the confusion matrix
        return matrix
